# assignment-1-

Saliency methods are used extensively to highlight the importance of input features in model predictions. These methods are mostly used in vision and language tasks, and their applications to time series data is relatively unexplored. In this paper, we set out to extensively compare the performance of various saliency-based interpretability methods across diverse neural architectures, including Recurrent Neural Network, Temporal Convolutional Networks, and Transformers in a new benchmark † of synthetic time series data. We propose and report multiple metrics to empirically evaluate the performance of saliency methods for detecting feature importance over time using both precision (i.e., whether identified features contain meaningful signals) and recall (i.e., the number of features with signal identified as important). Through several experiments, we show that (i) in general, network architectures and saliency methods fail to reliably and accurately identify feature importance over time in time series data, (ii) this failure is mainly due to the conflation of time and feature domains, and (iii) the quality of saliency maps can be improved substantially by using our proposed two-step temporal saliency rescaling (TSR) approach that first calculates the importance of each time step before calculating the importance of each feature at a time step.
这个项目的目的在于着手在合成时间序列数据的新基准中，广泛地比较各种基于显著性的可解释性方法在各种神经体系结构（包括递归神经网络，时间卷积网络和变压器）中的性能。我们提出并报告了多个度量标准，以通过经验和召回率来评估随时间检测特征重要性的显着性方法的性能。通过多次实验，我们发现（i）通常，网络体系结构和显著性方法无法可靠地和准确地识别时间序列数据中随时间变化的特征重要性；（ii）这种失败主要是由于时间和特征域的混淆， （iii）通过使用我们提出的两步时间显着性重缩放（TSR）方法，可以显着提高显着性图的质量，该方法首先计算每个时间步长的重要性，然后再计算每个时间步长的重要性。
